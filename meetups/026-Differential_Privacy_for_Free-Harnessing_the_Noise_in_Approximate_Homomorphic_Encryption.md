<!-- Main header navigation -->
<p align="center">
  <img width="200" src="https://user-images.githubusercontent.com/5758427/180978488-db825482-5a58-4c7c-9589-c494a6f0be04.png"><br/>
  <a href="https://fhe-org.github.io">Home</a> | <a href="https://fhe-org.github.io/resources">Resources</a> | <a href="https://fhe-org.github.io/meetups/">Meetups</a> | <a href="https://fhe-org.github.io/conferences/conference-2024/">Conference 2024</a> | <a href="https://fhe-org.github.io/community">Join the community</a>
</p>
<hr/>
<!-- /Main header navigation -->

# Differential Privacy for Free? Harnessing the Noise In Approximate Homomorphic Encryption
#### by Tabitha Ogilvie - 2023.06.08
#### <a href="https://www.youtube.com/watch?v=J_abn1z9aN8&list=PLnbmMskCVh1chnSM8Jjy6Nk3IH6fpn7MM&index=1">Video recording</a> (Youtube) | <a href="https://github.com/FHE-org/fhe-org.github.io/files/11818765/026.Differential.Privacy.for.Free.pdf">Slides</a> (Github) | <a href="https://eprint.iacr.org/2023/701">Paper</a> (iacr) | <a href="https://discord.fhe.org">Join the discussion</a> (Discord)

![026 Meetup cover](https://github.com/FHE-org/fhe-org.github.io/assets/37557436/0270aaef-c4a1-446c-94fd-3f984a9f84cc)

# Abstract

In this meetup, we'll make a connection between two important ideas in the Privacy Enhancing Technologies ecosystem -- Homomorphic Encryption and Differential Privacy. While Homomorphic Encryption ensures that sensitive data is not exposed during computation, Differential Privacy guarantees that each data subject can maintain their privacy when we share the result of that computation.

During this talk, we'll look at noise growth in Homomorphic Encryption (HE), and investigate the possibility that this inherent noise can give Differential Privacy (DP) "for free". We will recap what we mean by HE, noise, and DP, before examining new results on the DP guarantees of the Approximate HE setting. We'll finish by applying our results to a case study: Ridge Regression Training via Gradient Descent.

# About the speaker

Tabitha is a PhD student in the Information Security Group at Royal Holloway, University of London, and has just completed a year long internship at Intel, as part of the Security and Privacy Research Group within Intel Labs. Her area of research is Privacy Enhancing Technologies and Privacy Preserving Machine Learning, with a focus on Homomorphic Encryption.

# Never miss an update

The newsletter where we post community announcements: https://fheorg.substack.com/

The discord server where you can discuss FHE related topics with the community: https://discord.fhe.org

Make sure to join either (or both) of these to stay informed about future events!
